{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# 实现lstm和lstmp的源码\n",
    "# 定义常量\n",
    "bs, T, i_size, h_size = 2, 3, 4, 5\n",
    "input = torch.randn(bs,T, i_size)\n",
    "c0 = torch.randn(bs, h_size)\n",
    "h0 = torch.randn(bs, h_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "lstm_layer = nn.LSTM(i_size, h_size, batch_first=True)\n",
    "outout, (h_n, c_n) = lstm_layer(input,(h0.unsqueeze(0), c0.unsqueeze(0)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0.1260, -0.0432,  0.0379,  0.3549,  0.1202],\n         [ 0.0614,  0.1587,  0.0958,  0.1778, -0.1328],\n         [-0.0757,  0.0426,  0.1516,  0.0110, -0.1496]],\n\n        [[ 0.2533, -0.1454,  0.2498,  0.2968,  0.1513],\n         [ 0.0933, -0.0966,  0.2524,  0.0680, -0.0801],\n         [ 0.1399, -0.1651,  0.1841,  0.2158, -0.1731]]],\n       grad_fn=<TransposeBackward0>)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0 torch.Size([20, 4])\n",
      "weight_hh_l0 torch.Size([20, 5])\n",
      "bias_ih_l0 torch.Size([20])\n",
      "bias_hh_l0 torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "for k, v in lstm_layer.named_parameters():\n",
    "    print(k,v.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 自己写一个LSTM模型\n",
    "def lstm_forward(input, initial_states, w_ih, w_hh, b_ih, b_hh):\n",
    "    h0, c0 = initial_states\n",
    "    bs, T, i_size = input.shape\n",
    "    prev_h = h0\n",
    "    prec_c = c0\n",
    "    w_ih #(4*h_size, i_size)\n",
    "    w_hh #(4*h_size, h_size)\n",
    "\n",
    "    batch_w_ih = w_ih.unsqueeze(0).tile(bs,1,1) #\n",
    "    batch_w_hh = w_hh.unsqueeze(0).tile(bs,1,1)\n",
    "    output_size = h_size\n",
    "    outout = torch.zeros(bs, T, output_size) #输出序列\n",
    "\n",
    "    for t in range(T):\n",
    "        x = input[:,t,:] #当前时刻的输入向量[bs, i_size]\n",
    "        w_times_x = torch.bmm(batch_w_ih, x.unsqueeze(-1)) #[bs,4*h_size,1]\n",
    "        w_times_x = w_times_x.squeeze(-1)\n",
    "        w_times_h_prev = torch.bmm(batch_w_hh, prev_h.unsqueeze(-1))\n",
    "        w_times_h_prev = w_times_h_prev.squeeze(-1)\n",
    "\n",
    "        # 分别计算输入们(i)、遗忘门(f)，cell门(g)、输出门(0)\n",
    "        i_t = torch.sigmoid(w_times_x[:,:h_size] + w_times_h_prev[:,:h_size] + b_ih[:h_size] + b_hh[:h_size])\n",
    "        f_t = torch.sigmoid(w_times_x[:,h_size:2*h_size] + w_times_h_prev[:,h_size:2*h_size] + b_ih[h_size:2*h_size] + b_hh[h_size:2*h_size])\n",
    "        g_t = torch.tanh(w_times_x[:,2*h_size:3*h_size] + w_times_h_prev[:,2*h_size:3*h_size] + b_ih[2*h_size:3*h_size] + b_hh[2*h_size:3*h_size])\n",
    "        o_t = torch.sigmoid(w_times_x[:,3*h_size:4*h_size] + w_times_h_prev[:,3*h_size:4*h_size] + b_ih[3*h_size:4*h_size] + b_hh[3*h_size:4*h_size])\n",
    "\n",
    "        prev_c = f_t*prec_c + i_t*g_t\n",
    "        prev_h = o_t*torch.tanh(prev_c)\n",
    "\n",
    "        outout[:,t,:] = prev_h\n",
    "\n",
    "    return outout, (prev_h, prev_c)\n",
    "\n",
    "output_custom, (h_final_custom, c_final_custom) = lstm_forward(input, (h0,c0), lstm_layer.weight_ih_l0, lstm_layer.weight_hh_l0,lstm_layer.bias_ih_l0, lstm_layer.bias_hh_l0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1260, -0.0432,  0.0379,  0.3549,  0.1202],\n",
      "         [ 0.0650,  0.2983,  0.0375,  0.1358,  0.1681],\n",
      "         [-0.0190,  0.0811,  0.1171,  0.0596,  0.1556]],\n",
      "\n",
      "        [[ 0.2533, -0.1454,  0.2498,  0.2968,  0.1513],\n",
      "         [ 0.1153, -0.1831,  0.2243,  0.0433, -0.1640],\n",
      "         [ 0.1997, -0.2824,  0.1481,  0.3214, -0.0528]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "print(output_custom)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for k,v in output_custom."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}